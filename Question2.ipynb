{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "un_07izr0mCO"
   },
   "source": [
    "<h1 align=\"center\">An Introduction to Machine Learning - 25737</h1>\n",
    "<h4 align=\"center\">Dr. Sajjad Amini</h4>\n",
    "<h4 align=\"center\">Sharif University of Technology, Spring 2023</h4>\n",
    "\n",
    "**Student Name**:\n",
    "\n",
    "**Student ID**:\n",
    "\n",
    "# Effect of Overfitting\n",
    "\n",
    "In this exercise, we want to examine the effect of **overfitting**. As you learned in class, using too many features in training can result in a model with very low loss on the training set but high loss on the validation and test set. For this purpose, we have prepared a dataset in the `q2-train.npy`, `q2-valid.npy`, and `q2-test.npy` files for you. We know that `y` is a polynomial function of `x` in this dataset, meaning that \n",
    "\n",
    "$$\n",
    "y = \\sum_{i=0}^{k}a_ix^i\n",
    "$$\n",
    "\n",
    "However, we do not know the exact value of `k`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rcSNUeqT158e"
   },
   "source": [
    "## Importing Libraries\n",
    "\n",
    "First, we import the necessary libraries for this assignment. Please note that you should only use these libraries and no other libraries are acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UitW8b0J0jBa"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1x7BaU22F4k"
   },
   "source": [
    "## Reading Data and Preprocessing\n",
    "\n",
    "In this part of the assignment, you should read data from the `.npy` files. The data in `q2-train.npy` file is your training set and should be stored in the `X_train` and `Y_train` variables. Similarly, the data in `q2-valid.npy` file is your validation set, and the data in `q2-test.npy` file is your test set, which should be stored in `X_val`, `Y_val`, `X_test`, and `Y_test` respectively. You can use the `np.load` function to read the `.npy` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dDMeq10G2m0U"
   },
   "outputs": [],
   "source": [
    "X_train, Y_train, X_val, Y_val, X_test, Y_test = None, None, None, None, None, None\n",
    "\n",
    "### START CODE HERE ###\n",
    "data= np.load('q2-train.npy')\n",
    "X_train = data[:,0].copy()[np.newaxis].T\n",
    "Y_train = data[:,1].copy()[np.newaxis].T\n",
    "data= np.load('q2-valid.npy')\n",
    "X_val = data[:,0].copy()[np.newaxis].T\n",
    "Y_val = data[:,1].copy()[np.newaxis].T\n",
    "data= np.load('q2-test.npy')\n",
    "X_test = data[:,0].copy()[np.newaxis].T\n",
    "Y_test = data[:,1].copy()[np.newaxis].T\n",
    "\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyXpEfEa3Gw-"
   },
   "source": [
    "To find the best value of `k`, we want to change `k` from 1 to 12 and examine its effect on the validation set, and then choose the right value of `k`. For this purpose, we need to create a matrix with columns equal to $x^0$, $x^1$, $x^2$, ..., $x^k$ for every value of `k`. You can complete the following function to do this job. The function takes an $m \\times 1$ vector `X` containing values of input `x` and returns an $m \\times (k+1)$ matrix that has the properties mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DXw2tPO84Ksp"
   },
   "outputs": [],
   "source": [
    "def create_matrix(X):\n",
    "  '''\n",
    "  X: an m by 1 array \n",
    "  '''\n",
    "  new_X = None\n",
    "  ### START CODE HERE ###\n",
    "  k = 12\n",
    "  new_X = np.hstack(np.power(X, i) for i in range(k + 1))\n",
    "  ### END CODE HERE ###\n",
    "  return new_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCTuye7C5Aq3"
   },
   "source": [
    "## Validate Model\n",
    "\n",
    "Now, we want to train our model for every value of `k`. You can use any of the methods that we used in **Question 1** (gradient descent or direct calculation) for this purpose. The following function trains our model on the training set for a given value of `k`, and then returns the loss on the training set and validation set, as well as the weight vector `w`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9lfWITgf7yQH"
   },
   "outputs": [],
   "source": [
    "# If you need any other function for training write it here\n",
    "# (like gradient descent or anything else)\n",
    "def direct_method(X, Y):\n",
    "  '''\n",
    "  X: an m by (n+1) matrix which includes inputs\n",
    "  Y: an m by 1 vector which includes heating loads\n",
    "  '''\n",
    "  w = None\n",
    "  ### START CODE HERE ###\n",
    "  w = np.linalg.pinv((X.T @ X))@X.T@Y\n",
    "  ### END CODE HERE ###\n",
    "  return w\n",
    "\n",
    "def loss(X, Y, w):\n",
    "  '''\n",
    "  X: an m by (n+1) matrix which includes inputs\n",
    "  Y: an m by 1 vector which includes heating loads\n",
    "  w: an (n+1) by 1 weight vector\n",
    "  '''\n",
    "  #print(X)\n",
    "  m, n = X.shape\n",
    "  \n",
    "  ### START CODE HERE ###\n",
    "  loss = 1/m*(np.linalg.norm(X@w - Y))**2\n",
    "  ### END CODE HERE ###\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JaIs631q508z"
   },
   "outputs": [],
   "source": [
    "def train(X_train, Y_train, X_val, Y_val, k):\n",
    "  '''\n",
    "  X_train: an m_train by 1 vector contains training points\n",
    "  Y_train: an m_train by 1 vector contains training values\n",
    "  X_val: an m_val by 1 vector contains validation points\n",
    "  Y_val: an m_val by 1 vector contains validation values\n",
    "  k: degree of polynomial\n",
    "  '''\n",
    "  w, loss_train, loss_val = None, None , None\n",
    "  ### START CODE HERE ###\n",
    "  X_new = create_matrix(X_train)\n",
    "  #print(X_new)\n",
    "  w = direct_method(X_new[:,0:k+1],Y_train)\n",
    "  loss_train = loss(X_new[:,0:k+1],Y_train,w)\n",
    "  X_new = create_matrix(X_val)\n",
    "  loss_val = loss(X_new[:,0:k+1],Y_val,w)\n",
    "\n",
    "  ### END CODE HERE ###\n",
    "  return w, loss_train, loss_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAsZfxCu6YEf"
   },
   "source": [
    "In the cell below, you can change the value of `k` between 1 and 12 and plot the loss on the training and validation set as a function of `k` in the same plot.\n",
    "\n",
    "**Question**: Discuss about the effect of $k$.\n",
    "\n",
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "knUTXtOv66Wx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-e7be10a3742e>:8: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  new_X = np.hstack(np.power(X, i) for i in range(k + 1))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "for k in range(1,12):\n",
    "    w , loss_train, loss_val = train(X_train, Y_train, X_val, Y_val, k)\n",
    "    plt.plot(k,loss_train,'*',color='r')\n",
    "    plt.plot(k,loss_val,'o',color='b')\n",
    "    \n",
    "plt.show()\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0M1d2Ez7JLJ"
   },
   "source": [
    "## Evaluating Model\n",
    "\n",
    "In the cell below find the loss of your best model on the test set.\n",
    "\n",
    "**Question**: Why we need test set?\n",
    "\n",
    "**Answer**: To examine the model we fitted to the training set with the parameters we chose based on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Ex1P5H0A7emE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_test is 0.11791424797203304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-e7be10a3742e>:8: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  new_X = np.hstack(np.power(X, i) for i in range(k + 1))\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "w , loss_train, loss_test = train(X_train, Y_train, X_test, Y_test, k=8)\n",
    "print(\"loss_test is {}\".format(loss_test))\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
